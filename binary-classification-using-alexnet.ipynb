{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torchvision","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# Define transformations for the training and validation datasets\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),  # Resize to the input size of AlexNet\n        transforms.RandomHorizontalFlip(),  # Data augmentation\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Pre-trained models are trained on ImageNet\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# Define directories for training and validation datasets\ndata_dir = 'animal'  # Change this to your dataset directory\n\n# Create datasets\nimage_datasets = {x: datasets.ImageFolder(root=f'{data_dir}/{x}', transform=data_transforms[x])\n                  for x in ['train', 'valid']}\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True)\n               for x in ['train', 'valid']}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torchvision\nfrom torchvision import datasets, transforms\nimport numpy as np\n\n# Define transformations for displaying images\ntransform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n\n# Load datasets (assuming they are already organized in train and valid folders)\ndata_dir = 'animal'  # Replace with your dataset path\ntrain_dataset = datasets.ImageFolder(root=data_dir + '/train', transform=transform)\n\n# Create a DataLoader for the training dataset\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=6, shuffle=True)\n\n# Function to show images\ndef imshow(imgs, labels):\n    img_grid = torchvision.utils.make_grid(imgs)\n    img_grid = img_grid / 2 + 0.5  # Unnormalize\n    npimg = img_grid.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.title(\"Labels: \" + ' '.join(f'{train_dataset.classes[labels[j]]}' for j in range(len(labels))))\n    plt.show()\n\n# Get a batch of training data\nimages, labels = next(iter(train_loader))\n\n# Show images\nimshow(images, labels)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modify the classifier for binary classification\nimport torch\nimport torch.nn as nn\nfrom torchvision import models\n\n# Load the pre-trained AlexNet model\nalexnet = models.alexnet(pretrained=True)\n\n# Modify the classifier to output 2 classes for binary classification\nnum_ftrs = alexnet.classifier[6].in_features\nalexnet.classifier[6] = nn.Linear(num_ftrs, 2)  # 2 classes for binary classification\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all the convolutional base layers\nfor param in alexnet.features.parameters():\n    param.requires_grad = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nalexnet = alexnet.to(device)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(alexnet.classifier.parameters(), lr=0.001)\n\n# Training loop\ndef train_model(model, criterion, optimizer, num_epochs=10):\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()  # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward pass\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    loss = criterion(outputs, labels)\n                    _, preds = torch.max(outputs, 1)\n\n                    # Backward pass and optimization\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n    return model\n\n# Train the model\nmodel_ft = train_model(alexnet, criterion, optimizer, num_epochs=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Evaluate the model performance on the validation set\ndef evaluate_model(model):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in dataloaders['valid']:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f'Model accuracy on the validation set: {accuracy:.4f}')\n\n# Evaluate the trained model\nevaluate_model(model_ft)","metadata":{},"execution_count":null,"outputs":[]}]}